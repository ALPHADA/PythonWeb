
### 딥러닝 개요

- 스케치 투 코드(Sketch2Code)

![image](https://github.com/user-attachments/assets/90978edb-d464-44c1-9f82-8ba8eed9b630)

- 어도비 AI

<img width="605" alt="스크린샷 2024-08-01 오전 12 07 03" src="https://github.com/user-attachments/assets/1d81d812-53c2-4ff2-acb9-d2668a932e75">

- Suno AI

<img width="1137" alt="스크린샷 2024-08-01 오전 12 08 33" src="https://github.com/user-attachments/assets/62e1c053-5b9b-488e-8430-af20d423d767">

- 머신러닝

<img width="598" alt="스크린샷 2024-08-01 오전 12 09 47" src="https://github.com/user-attachments/assets/1078f291-a686-462c-977b-4ff11752436e">

- 기존의 머신러닝은 사전 지식이 필요하며, 데이터를 가이드라인에 맞춰 정리해주어야 했습니다. 반면에 딥러닝은 이러한 가이드라인 없이도 컴퓨터가 데이터를 통해 학습하고 패턴을 찾아냅니다.
- 딥러닝이란, 대규모 데이터에서 자동으로 특징을 추출해 중요한 패턴 및 규칙을 학습하고, 이를 토대로 의사 결정이나 예측 등을 수행하는 기술입니다.

![image](https://github.com/user-attachments/assets/ab4ad498-8fb3-44f2-9344-1c36e49145ab)

- 예를 들면 특정사진의 동물이 개인지 고양이인지 분류하도록 한다면?
  - 머신러닝의 경우 개와 고양이의 구별되는 큰 특징들만 뽑아 컴퓨터에게 전달 시키지만,
  - 딥러닝은 개, 고양이 사진 자체를 컴퓨터가 학습하도록 합니다.
![image](https://github.com/user-attachments/assets/be147944-b889-4050-87e9-951a4788743c)


- 딥러닝의 기본 개념은 신경망(Neural Network)을 기반으로 합니다.
- 신경망은 인간의 뇌와 유사한 구조로, 뉴런과 시냅스를 모방하여 설계되었습니다.

<img width="899" alt="스크린샷 2024-08-01 오전 12 15 02" src="https://github.com/user-attachments/assets/6e5d352e-7b1e-4066-a657-b2ade39a8bf7">
<img width="539" alt="스크린샷 2024-08-01 오전 12 15 38" src="https://github.com/user-attachments/assets/4bf5846d-764b-4b3c-9038-b5fe67236ea9">

### 머신러닝 개념

<img width="816" alt="스크린샷 2024-08-01 오전 12 18 56" src="https://github.com/user-attachments/assets/5f437017-0bc9-49f7-809c-c54963816cbf">
<img width="837" alt="스크린샷 2024-08-01 오전 12 19 32" src="https://github.com/user-attachments/assets/b1ea31fb-e136-4d37-85b1-25ea801d7087">

- 스팸 메일
<img width="854" alt="스크린샷 2024-08-01 오전 12 19 55" src="https://github.com/user-attachments/assets/f4fab329-c27c-43c8-ba71-247073deafaf">


- 지도 학습 (Supervised Learning): 정답이 있는 데이터를 이용해 학습합니다. 
- 비지도 학습 (Unsupervised Learning): 정답이 없는 데이터를 이용해 학습합니다. 수많은 데이터를 가지고 기계가 스스로 유사한 것끼리 분류하거나 군집화하는 과정을 통해 패턴을 발견합니다. 
- 강화 학습 (Reinforcement Learning): 보상과 벌을 통해 학습하는 방법입니다.

<img width="795" alt="스크린샷 2024-08-01 오전 12 20 27" src="https://github.com/user-attachments/assets/5c1c119f-a9f6-4244-8890-b44b0e117219">
<img width="660" alt="스크린샷 2024-08-01 오전 12 20 51" src="https://github.com/user-attachments/assets/7f8377ea-f733-4861-bb20-ac859ee79e14">
<img width="877" alt="스크린샷 2024-08-01 오전 12 21 16" src="https://github.com/user-attachments/assets/e294c913-9649-47c3-94df-fe29dbd0cbcc">

- 사람이 직접 "6월 성적에 0.5를 곱하고, 9월 성적에 0.5를 곱해 더하면 수능 점수가 될 것이다"라고 예측할 수 있습니다.
- 이때 0.5라는 값은 가중치(weight)라고 부르며, 머신러닝에서는 기계가 이러한 가중치를 자동으로 조정하도록 학습시킬 수 있습니다.

<img width="868" alt="스크린샷 2024-08-01 오전 12 22 02" src="https://github.com/user-attachments/assets/486bb8df-d814-4a32-af79-726360d25df1">


<img width="871" alt="스크린샷 2024-08-01 오전 12 23 29" src="https://github.com/user-attachments/assets/f98d7636-3055-4d03-a092-c68927aaf2b1">
<img width="831" alt="스크린샷 2024-08-01 오전 12 24 10" src="https://github.com/user-attachments/assets/1f4bec43-dfcb-4682-9f3e-b899a534b5af">
<img width="859" alt="스크린샷 2024-08-01 오전 12 23 51" src="https://github.com/user-attachments/assets/efbd6de6-dfed-4450-96b8-95c45ead5dcc">


<img width="875" alt="스크린샷 2024-08-01 오전 12 25 16" src="https://github.com/user-attachments/assets/541b4c1d-717c-450a-b3b3-0979ed06717a">
<img width="868" alt="스크린샷 2024-08-01 오전 12 25 35" src="https://github.com/user-attachments/assets/a97313b1-8304-4ba7-af74-378711b53fdd">

- 딥러닝의 장점
<img width="342" alt="스크린샷 2024-08-01 오전 12 26 13" src="https://github.com/user-attachments/assets/66790de4-d8aa-40bb-ac5d-fe3df1d9e5ab">
<img width="518" alt="스크린샷 2024-08-01 오전 12 26 23" src="https://github.com/user-attachments/assets/93f98954-1afc-4429-ac87-781f8e61f2ee">
<img width="508" alt="스크린샷 2024-08-01 오전 12 26 35" src="https://github.com/user-attachments/assets/72d4ef13-4e3c-49ed-825b-d2bf873d487b">

### 뇌를 본딴 뉴럴네트워크

- 뉴런 시냅스
<img width="906" alt="스크린샷 2024-08-01 오전 12 27 33" src="https://github.com/user-attachments/assets/ea983622-f59d-49e9-bd46-218633ff3802">
<img width="638" alt="스크린샷 2024-08-01 오전 12 27 57" src="https://github.com/user-attachments/assets/ceb86c2e-fc5e-480c-8f73-6b2ccbb6b6e3">
<img width="724" alt="스크린샷 2024-08-01 오전 12 28 14" src="https://github.com/user-attachments/assets/d979877a-03ba-401a-9484-51932e5a98d9">

- 수능점수 예측
<img width="884" alt="스크린샷 2024-08-01 오전 12 28 47" src="https://github.com/user-attachments/assets/9b11c801-abbb-449f-81e5-afd8ae1237b2">
<img width="536" alt="스크린샷 2024-08-01 오전 12 29 22" src="https://github.com/user-attachments/assets/b9b8d681-ddf7-4fd3-a648-01336ce0bc1b">
<img width="518" alt="스크린샷 2024-08-01 오전 12 30 17" src="https://github.com/user-attachments/assets/06fd17c3-e1f0-462b-bbc2-47b14a581685">

- 사람 얼굴 구분
<img width="529" alt="스크린샷 2024-08-01 오전 12 30 32" src="https://github.com/user-attachments/assets/bcadcadf-a2a9-497b-a61b-7495cd2f1fba">
<img width="525" alt="스크린샷 2024-08-01 오전 12 31 00" src="https://github.com/user-attachments/assets/af4cabf6-057f-4e89-ad78-afe83a88dc57">

- 피처 추출(feature extraction)
<img width="785" alt="스크린샷 2024-08-01 오전 12 31 13" src="https://github.com/user-attachments/assets/2006b5bf-61b2-4573-9440-4a6a82888efb">

- 뉴럴 네트워크
<img width="519" alt="스크린샷 2024-08-01 오전 12 32 07" src="https://github.com/user-attachments/assets/a0f646b8-79fa-4492-9c9b-140ad1ddf690">


### 손실함수 (loss function)

- 히든 레이어
- 각 요소는 '노드'라고 부르며, 이 노드들은 숫자로 표현 (노드의 값은 이전 노드들과의 연결을 통해 계산)
<img width="527" alt="스크린샷 2024-08-01 오전 12 33 09" src="https://github.com/user-attachments/assets/65605677-462d-4e1e-b61c-6a6187015e4f">
<img width="510" alt="스크린샷 2024-08-01 오전 12 34 47" src="https://github.com/user-attachments/assets/a042aa06-f9f0-490d-b4e9-1e8d7ce479fa">

<img width="517" alt="스크린샷 2024-08-01 오전 12 35 28" src="https://github.com/user-attachments/assets/480721e1-e5af-4621-b02c-ef56a5099fa4">
<img width="687" alt="스크린샷 2024-08-01 오전 12 35 46" src="https://github.com/user-attachments/assets/e2fa803c-d8f1-4493-b592-456c85bb388a">

<img width="512" alt="스크린샷 2024-08-01 오전 12 36 21" src="https://github.com/user-attachments/assets/13320e1b-d107-45b5-8f0b-2897f02ac21a">

- 예측된 값과 실제 값의 차이를 오차(error)라고 합니다. 
<img width="516" alt="스크린샷 2024-08-01 오전 12 36 48" src="https://github.com/user-attachments/assets/c73c267d-b7c3-47a9-be06-7cbc97d1f0b9">
<img width="861" alt="스크린샷 2024-08-01 오전 12 58 18" src="https://github.com/user-attachments/assets/7b5a2f87-6075-43d1-8065-968efb2e422d">
<img width="849" alt="스크린샷 2024-08-01 오전 12 37 44" src="https://github.com/user-attachments/assets/22a5fefa-b851-434c-a42a-74e2cc693a6e">


- '로스 함수' 또는 '코스트 함수'를 사용하여 모델의 정확도를 평가
<img width="279" alt="스크린샷 2024-08-01 오전 12 38 25" src="https://github.com/user-attachments/assets/b4d9c3bf-19b9-48ce-b76a-38b7fbab6a1f">
<img width="394" alt="스크린샷 2024-08-01 오전 12 38 45" src="https://github.com/user-attachments/assets/2ce41dfb-4fe8-4b56-9e7a-daca1d5fb164">

### 활성함수가 없으면 뉴럴네트워크가 아님

<img width="525" alt="스크린샷 2024-08-01 오전 12 39 31" src="https://github.com/user-attachments/assets/a2b51419-0426-481d-a3ca-c29ac34671a0">
<img width="878" alt="스크린샷 2024-08-01 오전 12 39 57" src="https://github.com/user-attachments/assets/1bf5b54c-faad-402d-9daa-753b83506adc">

- 활성함수
<img width="535" alt="스크린샷 2024-08-01 오전 12 40 30" src="https://github.com/user-attachments/assets/639e1f84-b79d-4f12-af5a-c31c7709048d">
<img width="812" alt="스크린샷 2024-08-01 오전 12 40 52" src="https://github.com/user-attachments/assets/dd7ac3be-5556-4349-8902-97d46ba1fd01">

- 시그모이드 함수
- 입력값을 0과 1 사이의 값으로 변환
<img width="883" alt="스크린샷 2024-08-01 오전 12 41 21" src="https://github.com/user-attachments/assets/2d99d667-097e-4281-a360-59865cf69918">

- 하이퍼볼릭 탄젠트 함수(Tanh)
- 입력값을 -1과 1 사이로 변환
<img width="876" alt="스크린샷 2024-08-01 오전 12 41 39" src="https://github.com/user-attachments/assets/93789d5a-a424-406b-b971-c756465784b7">

- 렐루 함수(ReLU)
- 양수는 그대로 유지하고, 음수는 0으로 변환
<img width="409" alt="스크린샷 2024-08-01 오전 12 42 31" src="https://github.com/user-attachments/assets/68eeb0ca-ad3c-43ce-8bf9-1ad51e8bce34">

- 비선형적인 예측 가능
<img width="688" alt="스크린샷 2024-08-01 오전 12 43 12" src="https://github.com/user-attachments/assets/9b218c3f-18b8-4306-af3a-e081e229c33e">
<img width="690" alt="스크린샷 2024-08-01 오전 12 43 30" src="https://github.com/user-attachments/assets/e24f3172-be4f-4fbf-adb3-9fe1fe2d88cb">

- 출력값 
<img width="556" alt="스크린샷 2024-08-01 오전 12 44 15" src="https://github.com/user-attachments/assets/33853ce9-702b-4925-a0da-3ebae9ef7222">

### 경사하강법

<img width="511" alt="스크린샷 2024-08-01 오전 1 30 30" src="https://github.com/user-attachments/assets/67bd9c0c-a4ed-4223-b1a4-1c10f40677f4">
<img width="520" alt="스크린샷 2024-08-01 오전 1 30 16" src="https://github.com/user-attachments/assets/931e4db6-e294-4482-8c9f-162232a998a8">

- 예측값
<img width="497" alt="스크린샷 2024-08-01 오전 1 31 28" src="https://github.com/user-attachments/assets/a00e1ee7-1c68-4add-9a8a-1278c63b445c">
<img width="504" alt="스크린샷 2024-08-01 오전 1 32 04" src="https://github.com/user-attachments/assets/f1dc5018-35a8-434e-92a4-aecbfe8c7137">

- 오차를 최소화하는 가중치 w 값 찾기
<img width="828" alt="스크린샷 2024-08-01 오전 1 32 26" src="https://github.com/user-attachments/assets/0fb05cb9-5e59-4cd3-839e-4151a16b6460">
<img width="425" alt="스크린샷 2024-08-01 오전 1 32 59" src="https://github.com/user-attachments/assets/ce0001ab-875b-47fd-8fa4-9ec8e92f6224">

- 흐름
<img width="413" alt="스크린샷 2024-08-01 오전 1 33 13" src="https://github.com/user-attachments/assets/5a3fa1d3-35cc-4a5b-adba-c41d09d46be3">
<img width="413" alt="스크린샷 2024-08-01 오전 1 33 49" src="https://github.com/user-attachments/assets/514fcace-cf79-4fe7-8c4c-fa6074fd5f7e">
<img width="413" alt="스크린샷 2024-08-01 오전 1 34 02" src="https://github.com/user-attachments/assets/a0319562-60cd-46f9-8f04-0420eea23479">

- 경사하강법
<img width="812" alt="스크린샷 2024-08-01 오전 1 34 23" src="https://github.com/user-attachments/assets/217ac37e-a981-4ace-9f90-50cad329fc66">
<img width="420" alt="스크린샷 2024-08-01 오전 1 35 12" src="https://github.com/user-attachments/assets/4ae0a7dc-aaff-4893-aa8d-703dd72ea291">
<img width="428" alt="스크린샷 2024-08-01 오전 1 35 27" src="https://github.com/user-attachments/assets/8d76b940-0225-492d-bb0c-17bee7f49e75">
<img width="438" alt="스크린샷 2024-08-01 오전 1 35 36" src="https://github.com/user-attachments/assets/62baf5c2-ea4f-47fc-b67a-24253aec18c4">

- 기울기 1
<img width="423" alt="스크린샷 2024-08-01 오전 1 35 55" src="https://github.com/user-attachments/assets/792219e6-709f-4e89-a607-8e7cb9bdf1be">

- 기울기 -1
<img width="426" alt="스크린샷 2024-08-01 오전 1 36 09" src="https://github.com/user-attachments/assets/afbf1242-95c4-4253-869d-6882157bee9f">
<img width="412" alt="스크린샷 2024-08-01 오전 1 36 29" src="https://github.com/user-attachments/assets/0e73d10f-615f-4510-9219-16a94de5fd16">

- 경사하강법 정리
<img width="883" alt="스크린샷 2024-08-01 오전 1 37 35" src="https://github.com/user-attachments/assets/c2de4f0a-b65e-497c-9e30-0ffba1bd2119">
<img width="368" alt="스크린샷 2024-08-01 오전 1 38 09" src="https://github.com/user-attachments/assets/ae13c598-24e8-4784-b7fa-630e35751d80">
<img width="902" alt="스크린샷 2024-08-01 오전 1 38 30" src="https://github.com/user-attachments/assets/9fc8b2b0-8259-4c97-8991-7b9fe248342b">
<img width="730" alt="스크린샷 2024-08-01 오전 1 38 40" src="https://github.com/user-attachments/assets/6b44fa8b-1683-4117-bafd-b2f8b9827a6e">
<img width="467" alt="스크린샷 2024-08-01 오전 1 40 35" src="https://github.com/user-attachments/assets/ef9e726b-50b6-442e-ab09-28df515eb9ac">

- 기울기 0
<img width="438" alt="스크린샷 2024-08-01 오전 1 39 24" src="https://github.com/user-attachments/assets/83b41d4e-b049-4d0a-be1d-a52580d606dd">
<img width="433" alt="스크린샷 2024-08-01 오전 1 39 38" src="https://github.com/user-attachments/assets/65c5c5d6-9a4a-4f48-ac0b-8b3cc413f9c7">
<img width="795" alt="스크린샷 2024-08-01 오전 1 39 53" src="https://github.com/user-attachments/assets/24654ee0-efb3-44b6-b3f9-e82f3ca89b14">
<img width="347" alt="스크린샷 2024-08-01 오전 1 40 12" src="https://github.com/user-attachments/assets/fa669c44-6e82-407b-9467-aa109f3528d0">

- 가짜 최저점
<img width="921" alt="스크린샷 2024-08-01 오전 1 40 59" src="https://github.com/user-attachments/assets/e9dc5483-bc4b-4844-8594-04d5ff5b5f0c">
<img width="929" alt="스크린샷 2024-08-01 오전 1 41 22" src="https://github.com/user-attachments/assets/c84c0e8d-0c86-4d61-8eaa-f1dbacac9463">
<img width="355" alt="스크린샷 2024-08-01 오전 1 41 41" src="https://github.com/user-attachments/assets/25e09b3d-a090-42b1-8956-a8c2e1a76626">
<img width="543" alt="스크린샷 2024-08-01 오전 1 41 53" src="https://github.com/user-attachments/assets/4d41128e-b91b-4e89-9942-ac1b4d04afd4">

- 옵티마이저
<img width="915" alt="스크린샷 2024-08-01 오전 1 42 12" src="https://github.com/user-attachments/assets/14405e67-b4d9-499a-ba12-d00c7c5c795f">


<img width="397" alt="스크린샷 2024-08-01 오전 1 42 40" src="https://github.com/user-attachments/assets/e89d2fd2-197e-4013-8ac4-34ced20e7c39">

### Tensorflow 2 기초 빠르게 정리

```python
import tensorflow as tf

tensor = tf.constant([1, 2, 3])
print(tensor)
```

- 텐서가 필요한 이유
  - 행렬로 인풋/w값 저장 가능
  - node 값 계산식 쉬워짐
<img width="599" alt="스크린샷 2024-08-01 오전 7 52 49" src="https://github.com/user-attachments/assets/e7a4f86c-034d-4ee9-b6a6-f67bbd9edadd">

```python
tensor1 = tf.constant([1, 2, 3])
tensor2 = tf.constant([4, 5, 6])
result = tf.add(tensor1, tensor2)
print(result)
print(tensor1 + tensor2)
# add, subtract, divide, multiply
# matmul : A와 B행렬의 곱 (AB) - dot product
```

<img width="452" alt="스크린샷 2024-08-01 오전 7 57 11" src="https://github.com/user-attachments/assets/35f07e60-0101-497a-9388-23811355a5d7">

- 2차원 텐서
```python
tensor3 = tf.constant([[1, 2], [3, 4]])
print(tensor3)
```

- 텐서의 차원
```python
print(tensor3.shape)
```

- 0만 담긴 텐서
```python
tensor4 = tf.zeros(10)
print(tensor4)
tensor4 = tf.zeros([2,2])
print(tensor4)
tensor4 = tf.zeros([2,2,3])
print(tensor4)
```

- 데이터 타입
  - 정수 : int
  - 실수 : float (딥러닝)
```python

tensor1 = tf.constant([1.0, 2, 3])
tensor2 = tf.constant([4, 5, 6], tf.float32)
tensor3 = tf.constant([[1, 2], [3, 4]])
print(tensor3)
```

- 변수(Variable)
  - 값 수정 가능
```python
w = tf.Variable(1.0)
print(w)
print(w.numpy())
w2 = tf.Variable([1.0, 2.0, 3.0])
print(w2)
w.assign(2)
```

### Tensorflow 2로 해보는 간단한 Linear Regression 선형회귀 예측
```
키: 170cm, 신발 사이즈: 260
키: 180cm, 신발 사이즈: 270
...
```

`신발 사이즈 = a×키+b`

```python
height = [170, 180, 175, 160]
shoe = [260, 270, 265, 255]

??? = a*height + b
```

![스크린샷 2024-08-01 오후 3 09 14](https://github.com/user-attachments/assets/3576a8f2-343d-4072-8da2-0c25fb5e6643)
![스크린샷 2024-08-01 오후 3 09 41](https://github.com/user-attachments/assets/c7257768-416d-4a2f-a403-d1d08d7beca3)

- tf.Variable을 사용하여 초기값을 설정
```python
import tensorflow as tf

height = 170
shoe = 260

# shoe = a * height + b

a = tf.Variable(0.1)
b = tf.Variable(0.2)
```

- 경사 하강법을 통해 학습을 진행
  - 옵티마이저 정의
```python
optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)
# Adam 옵티마이저는 경사 하강법을 이용하여 변수들을 업데이트
```

- 손실 함수 정의
  - 예측 값과 실제 값 사이의 오차를 계산하는 함수
  - 평균 제곱 오차(MSE)를 사용

```python
def loss_fn():
    # return 실제값 - 예측값
    y_pred = a * height + b
    y_true = shoe
    return tf.square(y_pred - y_true) # 제곱 계산
...
opt.minizize(loss_fn, var_list=[a, b]) # 경사하강 1번 (a, b 가 1번 수정됨)
```

- 반복
```python
for i in range(300):
    optimizer.minimize(loss_fn, var_list=[a, b])
    print(a.numpy(), b.numpy())
```

- 결과 확인
```python
predicted_shoe_size = a.numpy() * 180 + b.numpy()
print(predicted_shoe_size)
```

- 최종
```python
import tensorflow as tf

height = 170
shoe = 260
# shoe = a * height + b

a = tf.Variable(0.1)
b = tf.Variable(0.2)

def loss_fn():
    # return 실제값 - 예측값
    y_pred = a * height + b
    y_true = shoe
    return tf.square(y_pred - y_true)

optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)
opt.minizize(loss_fn, var_list=[a, b]) # 경사하강 1번 (a, b 가 1번 수정됨)

for i in range(300):
    optimizer.minimize(loss_fn, var_list=[a, b])
    print(a.numpy(), b.numpy())

predicted_shoe_size = a.numpy() * 180 + b.numpy()
print(predicted_shoe_size)
```

### 대학 합격 예측 AI 만들기 (풀버전)
#### (Part 1) Keras로 모델 만들기

- 대학 합격 데이터
  - admit : 1은 합격, 0은 불합격
  - gre : 영어성적
  - gpa : 학점
  - rank : 지원한 대학 수준
![스크린샷 2024-08-01 오후 3 50 36](https://github.com/user-attachments/assets/65a84962-844d-4bab-9c09-a907a48edf3e)

- 딥러닝으로 합격 확률 구하기

1. 딥러닝 model 디자인

- 프로젝트 설정
```python
import tensorflow as tf
from tensorflow.keras import layers

# keras 텐서플로우에 포함된 고수준 API로, 딥러닝 모델을 쉽게 만들 수 있음
tf.keras.Sequential([
  레이어1,
  레이어2,
  레이어3
]) # 딥러닝 모델
```
<img width="625" alt="스크린샷 2024-08-02 오전 12 42 21" src="https://github.com/user-attachments/assets/0e246cab-efe2-440f-b3ff-ae194265d431">

- 모델 구성
```python
model = tf.keras.Sequential([
    layers.Dense(64), # 레이어 갯수/노드 갯수 적절히
    layers.Dense(128),
    layers.Dense(1) #  마지막 레이어는 1개의 노드 (예측 결과)
])
```
```python
# 레이어에 activation function 넣기
# sigmoid, tanh, relu, softmax, leakyRelu
model = tf.keras.Sequential([
    layers.Dense(64, activation='relu'),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])
# 0과 1 사이의 확률 값을 출력하는 sigmoid 선택
```
<img width="306" alt="스크린샷 2024-08-02 오전 12 46 55" src="https://github.com/user-attachments/assets/3b83ad1a-ffe4-489f-add5-111f9bef379e">

- 마지막 출력 결과가 0.2 => 입학확률 20%
- 마지막 출력 결과가 0.9 => 입학확률 90%

2. 모델 컴파일

- 모델을 컴파일할 때는 옵티마이저, 손실 함수, 메트릭스를 정의
```python
model.compile(optimizer=???, loss=???, metrics=['accuracy'])

# adam, adagrad, adadelta, rmsprop, sgd 등
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
```
= 옵티마이저: 경사 하강법을 사용해 모델을 학습. (adam 옵티마이저는 일반적으로 좋은 성능을 가짐)
- 손실 함수: binary_crossentropy를 사용해 0과 1 사이의 확률을 예측.
- 메트릭스: 모델의 성능을 평가하는 기준으로, 여기서는 정확도(accuracy)를 사용.
<img width="777" alt="스크린샷 2024-08-02 오전 12 53 01" src="https://github.com/user-attachments/assets/e0ad09ae-3661-4fb2-9ffa-c7fadda51e1b">
<img width="428" alt="스크린샷 2024-08-02 오전 12 54 13" src="https://github.com/user-attachments/assets/fa740d48-c42e-4533-8071-e2cb122cad69">

3. 모델 학습

```python
model.fit( x데이터, y데이터, epochs=100)

# x데이터 = [ [학생1데이터], [학생2데이터], ... ]
# x데이터 = [ [380, 3.21, 3], [660, 3.67, 3], [], ... ]
# y데이터 = [ 정답1, 정답2, 정답3, ...]
# y데이터 = [ [0], [1], [1], [1], ...]
```
- x데이터: 학습 데이터
- y데이터: 실제 정답
- epochs: 전체 데이터셋을 한 번 학습시키는 과정. 몇 번 학습할지 정하는 변수


#### (Part 2) 데이터 준비하기
1. 데이터 로드
```python
import pandas as pd

data = pd.read_csv('admission_data.csv')
print(data)

# exit()
```

2. 데이터 전처리
- 데이터를 학습시키기 전에 결측치를 처리하고 필요한 부분을 추출합니다.
- 빈 부분은 평균값을 넣거나, 행을 삭제하거나 어떻게 처리할지 선택
```python
# 빈 칸 확인
print(data.isnull().sum())

# 빈 칸 or NaN 있는 행을 제거
data = data.dropna()
# data.fillna(100) 빈칸을 100으로 세팅

print(data.isnull().sum())
```
이 코드는 데이터에서 결측치가 있는 행을 제거합니다. 필요에 따라 결측치를 특정 값으로 채울 수도 있습니다.

- 참고
```
print(data['gpa'])
print(data['gpa'].min())
print(data['gpa'].max())
print(data['gpa'].count())
```

3. 데이터 준비
- 모델에 입력할 X 데이터와 출력할 y 데이터를 준비

```python
# x데이터 = [ [학생1데이터], [학생2데이터], ... ]
# x데이터 = [ [380, 3.21, 3], [660, 3.67, 3], [], ... ]
# y데이터 = [ 정답1, 정답2, 정답3, ...]
# y데이터 = [ [0], [1], [1], [1], ...]

y = data['admit'].values
print(y)

X = []
for i, rows in data.iterrows():
  print(rows)
  print(rows['gre'])
  print(rows['gpa'])
  print(rows['rank'])
  x.append( [rows['gre'], rows['gpa'], rows['rank'] ] ) # [640, 3.19, 4]

print(x)
```


### (Part 3) 학습시키기 & 예측해보기
1. 모델 학습
- 이제 준비된 데이터를 사용해 모델을 학습시킵니다.

```python
model.fit(x, y, epochs=100) # w값 최적화해주세요~

# python list 가 아니라 numpy array, tf tensor 를 넣어야 함
# 일반 리스트를 numpy array 로 변환해서 넣기
import numpy as np

model.fit(np.array(x), np.array(y), epochs=100)
```
- Epoch: 몇 번째 epoch 인지
- 0s: 소요시간
- loss: 현재 총 손실 (적을수록 좋음)
- accuracy: 모델의 정답률. 예측 값과 데이터가 얼마나 잘 맞는지 (높을수록 좋음)


2. 예측
- 모델이 학습된 후, 새로운 데이터를 입력하여 예측을 수행

```python
new_data = np.array([[750, 3.7, 3], [400, 2.1, 1]])
predictions = model.predict(new_data)
print(predictions)
```

- 성능 향식
  - 데이터 전처리
  - 하이퍼파라미터 튜닝
    - 모델 학습 과정에서 사용자가 설정해야 하는 매개변수. 예를 들어, 학습률, 에포크 수, 레이어 수 등.

#### 결론
딥러닝 AI를 만들기 위해 해야할 일 
1. 모델 만들기
2. 데이터 준비하기
3. 데이터 집어넣고 학습하기
4. 새로운 데이터 예측하기

<img width="719" alt="스크린샷 2024-08-02 오전 1 26 43" src="https://github.com/user-attachments/assets/c41e550c-ff2b-420d-ad34-b146e841c786">

#### 용어 정리
- 레이어 (Layer): 신경망의 기본 구성 요소로, 입력 데이터가 입력되고 출력을 생성하는 함수의 모음. 각각의 레이어는 여러 개의 뉴런으로 구성됩니다.
- 노드 (Node): 신경망 레이어 내의 개별 계산 단위로, 하나의 뉴런이라고도 불립니다. 입력값을 받아 가중치를 곱하고 활성화 함수를 적용해 출력값을 생성합니다.
- 활성화 함수 (Activation Function): 입력 신호에 비선형성을 추가하여 신경망이 복잡한 패턴을 학습할 수 있도록 돕는 함수. 주요 활성화 함수로는 relu, sigmoid, tanh 등이 있습니다.
- 시그모이드 함수 (Sigmoid Function): 모든 값을 0과 1 사이로 압축하는 활성화 함수. 주로 확률 값을 예측할 때 사용됩니다.
- 경사 하강법 (Gradient Descent): 손실 함수의 기울기를 이용하여 가중치를 업데이트하는 최적화 알고리즘. 손실을 최소화하기 위해 학습합니다.
- 손실 함수 (Loss Function): 모델의 예측값과 실제값 간의 차이를 계산하는 함수. 손실 값이 작을수록 모델의 성능이 좋습니다. 예를 들어, binary_crossentropy는 이진 분류 문제에서 자주 사용됩니다.
- 옵티마이저 (Optimizer): 경사 하강법을 기반으로 가중치를 업데이트하는 알고리즘. adam, sgd 등이 대표적인 옵티마이저입니다.

### 인공 뉴런(퍼셉트론)
<img width="695" alt="스크린샷 2024-08-02 오전 1 22 44" src="https://github.com/user-attachments/assets/11de7226-7378-4d4f-87ca-c7a85cd0fd2a">

✔ 입력값과 가중치, 편향을 이용해 출력값을 내는 수학적 모델
✔ 퍼셉트론을 이용해 만든 모든 구조물을 인공 신경망이라고 부릅니다.
✔ 퍼셉트론을 하나 사용하면 단층 신경망, 퍼셉트론을 여러개 사용하면 다층 신경망이라 부릅니다.


