
### 딥러닝 개요

- 스케치 투 코드(Sketch2Code)

![image](https://github.com/user-attachments/assets/90978edb-d464-44c1-9f82-8ba8eed9b630)

- 어도비 AI

<img width="605" alt="스크린샷 2024-08-01 오전 12 07 03" src="https://github.com/user-attachments/assets/1d81d812-53c2-4ff2-acb9-d2668a932e75">

- Suno AI

<img width="1137" alt="스크린샷 2024-08-01 오전 12 08 33" src="https://github.com/user-attachments/assets/62e1c053-5b9b-488e-8430-af20d423d767">

- 머신러닝

<img width="598" alt="스크린샷 2024-08-01 오전 12 09 47" src="https://github.com/user-attachments/assets/1078f291-a686-462c-977b-4ff11752436e">

- 기존의 머신러닝은 사전 지식이 필요하며, 데이터를 가이드라인에 맞춰 정리해주어야 했습니다. 반면에 딥러닝은 이러한 가이드라인 없이도 컴퓨터가 데이터를 통해 학습하고 패턴을 찾아냅니다.
- 딥러닝이란, 대규모 데이터에서 자동으로 특징을 추출해 중요한 패턴 및 규칙을 학습하고, 이를 토대로 의사 결정이나 예측 등을 수행하는 기술입니다.

![image](https://github.com/user-attachments/assets/ab4ad498-8fb3-44f2-9344-1c36e49145ab)

- 예를 들면 특정사진의 동물이 개인지 고양이인지 분류하도록 한다면?
  - 머신러닝의 경우 개와 고양이의 구별되는 큰 특징들만 뽑아 컴퓨터에게 전달 시키지만,
  - 딥러닝은 개, 고양이 사진 자체를 컴퓨터가 학습하도록 합니다.
![image](https://github.com/user-attachments/assets/be147944-b889-4050-87e9-951a4788743c)


- 딥러닝의 기본 개념은 신경망(Neural Network)을 기반으로 합니다.
- 신경망은 인간의 뇌와 유사한 구조로, 뉴런과 시냅스를 모방하여 설계되었습니다.

<img width="899" alt="스크린샷 2024-08-01 오전 12 15 02" src="https://github.com/user-attachments/assets/6e5d352e-7b1e-4066-a657-b2ade39a8bf7">
<img width="539" alt="스크린샷 2024-08-01 오전 12 15 38" src="https://github.com/user-attachments/assets/4bf5846d-764b-4b3c-9038-b5fe67236ea9">

### 머신러닝 개념

<img width="816" alt="스크린샷 2024-08-01 오전 12 18 56" src="https://github.com/user-attachments/assets/5f437017-0bc9-49f7-809c-c54963816cbf">
<img width="837" alt="스크린샷 2024-08-01 오전 12 19 32" src="https://github.com/user-attachments/assets/b1ea31fb-e136-4d37-85b1-25ea801d7087">

- 스팸 메일
<img width="854" alt="스크린샷 2024-08-01 오전 12 19 55" src="https://github.com/user-attachments/assets/f4fab329-c27c-43c8-ba71-247073deafaf">


- 지도 학습 (Supervised Learning): 정답이 있는 데이터를 이용해 학습합니다. 
- 비지도 학습 (Unsupervised Learning): 정답이 없는 데이터를 이용해 학습합니다. 수많은 데이터를 가지고 기계가 스스로 유사한 것끼리 분류하거나 군집화하는 과정을 통해 패턴을 발견합니다. 
- 강화 학습 (Reinforcement Learning): 보상과 벌을 통해 학습하는 방법입니다.

<img width="795" alt="스크린샷 2024-08-01 오전 12 20 27" src="https://github.com/user-attachments/assets/5c1c119f-a9f6-4244-8890-b44b0e117219">
<img width="660" alt="스크린샷 2024-08-01 오전 12 20 51" src="https://github.com/user-attachments/assets/7f8377ea-f733-4861-bb20-ac859ee79e14">
<img width="877" alt="스크린샷 2024-08-01 오전 12 21 16" src="https://github.com/user-attachments/assets/e294c913-9649-47c3-94df-fe29dbd0cbcc">

- 사람이 직접 "6월 성적에 0.5를 곱하고, 9월 성적에 0.5를 곱해 더하면 수능 점수가 될 것이다"라고 예측할 수 있습니다.
- 이때 0.5라는 값은 가중치(weight)라고 부르며, 머신러닝에서는 기계가 이러한 가중치를 자동으로 조정하도록 학습시킬 수 있습니다.

<img width="868" alt="스크린샷 2024-08-01 오전 12 22 02" src="https://github.com/user-attachments/assets/486bb8df-d814-4a32-af79-726360d25df1">


<img width="871" alt="스크린샷 2024-08-01 오전 12 23 29" src="https://github.com/user-attachments/assets/f98d7636-3055-4d03-a092-c68927aaf2b1">
<img width="831" alt="스크린샷 2024-08-01 오전 12 24 10" src="https://github.com/user-attachments/assets/1f4bec43-dfcb-4682-9f3e-b899a534b5af">
<img width="859" alt="스크린샷 2024-08-01 오전 12 23 51" src="https://github.com/user-attachments/assets/efbd6de6-dfed-4450-96b8-95c45ead5dcc">


<img width="875" alt="스크린샷 2024-08-01 오전 12 25 16" src="https://github.com/user-attachments/assets/541b4c1d-717c-450a-b3b3-0979ed06717a">
<img width="868" alt="스크린샷 2024-08-01 오전 12 25 35" src="https://github.com/user-attachments/assets/a97313b1-8304-4ba7-af74-378711b53fdd">

- 딥러닝의 장점
<img width="342" alt="스크린샷 2024-08-01 오전 12 26 13" src="https://github.com/user-attachments/assets/66790de4-d8aa-40bb-ac5d-fe3df1d9e5ab">
<img width="518" alt="스크린샷 2024-08-01 오전 12 26 23" src="https://github.com/user-attachments/assets/93f98954-1afc-4429-ac87-781f8e61f2ee">
<img width="508" alt="스크린샷 2024-08-01 오전 12 26 35" src="https://github.com/user-attachments/assets/72d4ef13-4e3c-49ed-825b-d2bf873d487b">

### 뇌를 본딴 뉴럴네트워크 (컴퓨터가 사람처럼 생각하겠냐?)

- 뉴런 시냅스
<img width="906" alt="스크린샷 2024-08-01 오전 12 27 33" src="https://github.com/user-attachments/assets/ea983622-f59d-49e9-bd46-218633ff3802">
<img width="638" alt="스크린샷 2024-08-01 오전 12 27 57" src="https://github.com/user-attachments/assets/ceb86c2e-fc5e-480c-8f73-6b2ccbb6b6e3">
<img width="724" alt="스크린샷 2024-08-01 오전 12 28 14" src="https://github.com/user-attachments/assets/d979877a-03ba-401a-9484-51932e5a98d9">

- 수능점수 예측
<img width="884" alt="스크린샷 2024-08-01 오전 12 28 47" src="https://github.com/user-attachments/assets/9b11c801-abbb-449f-81e5-afd8ae1237b2">
<img width="536" alt="스크린샷 2024-08-01 오전 12 29 22" src="https://github.com/user-attachments/assets/b9b8d681-ddf7-4fd3-a648-01336ce0bc1b">
<img width="518" alt="스크린샷 2024-08-01 오전 12 30 17" src="https://github.com/user-attachments/assets/06fd17c3-e1f0-462b-bbc2-47b14a581685">

- 사람 얼굴 구분
<img width="529" alt="스크린샷 2024-08-01 오전 12 30 32" src="https://github.com/user-attachments/assets/bcadcadf-a2a9-497b-a61b-7495cd2f1fba">
<img width="525" alt="스크린샷 2024-08-01 오전 12 31 00" src="https://github.com/user-attachments/assets/af4cabf6-057f-4e89-ad78-afe83a88dc57">

- 피처 추출(feature extraction)
<img width="785" alt="스크린샷 2024-08-01 오전 12 31 13" src="https://github.com/user-attachments/assets/2006b5bf-61b2-4573-9440-4a6a82888efb">

- 뉴럴 네트워크
<img width="519" alt="스크린샷 2024-08-01 오전 12 32 07" src="https://github.com/user-attachments/assets/a0f646b8-79fa-4492-9c9b-140ad1ddf690">


### 손실함수 (loss function) 로 컴퓨터에게 오차를 알려줘야함

- 히든 레이어
- 각 요소는 '노드'라고 부르며, 이 노드들은 숫자로 표현 (노드의 값은 이전 노드들과의 연결을 통해 계산)
<img width="527" alt="스크린샷 2024-08-01 오전 12 33 09" src="https://github.com/user-attachments/assets/65605677-462d-4e1e-b61c-6a6187015e4f">
<img width="510" alt="스크린샷 2024-08-01 오전 12 34 47" src="https://github.com/user-attachments/assets/a042aa06-f9f0-490d-b4e9-1e8d7ce479fa">

<img width="517" alt="스크린샷 2024-08-01 오전 12 35 28" src="https://github.com/user-attachments/assets/480721e1-e5af-4621-b02c-ef56a5099fa4">
<img width="687" alt="스크린샷 2024-08-01 오전 12 35 46" src="https://github.com/user-attachments/assets/e2fa803c-d8f1-4493-b592-456c85bb388a">

<img width="512" alt="스크린샷 2024-08-01 오전 12 36 21" src="https://github.com/user-attachments/assets/13320e1b-d107-45b5-8f0b-2897f02ac21a">

- 예측된 값과 실제 값의 차이를 오차(error)라고 합니다. 
<img width="516" alt="스크린샷 2024-08-01 오전 12 36 48" src="https://github.com/user-attachments/assets/c73c267d-b7c3-47a9-be06-7cbc97d1f0b9">
<img width="861" alt="스크린샷 2024-08-01 오전 12 58 18" src="https://github.com/user-attachments/assets/7b5a2f87-6075-43d1-8065-968efb2e422d">
<img width="849" alt="스크린샷 2024-08-01 오전 12 37 44" src="https://github.com/user-attachments/assets/22a5fefa-b851-434c-a42a-74e2cc693a6e">


- '로스 함수' 또는 '코스트 함수'를 사용하여 모델의 정확도를 평가
<img width="279" alt="스크린샷 2024-08-01 오전 12 38 25" src="https://github.com/user-attachments/assets/b4d9c3bf-19b9-48ce-b76a-38b7fbab6a1f">
<img width="394" alt="스크린샷 2024-08-01 오전 12 38 45" src="https://github.com/user-attachments/assets/2ce41dfb-4fe8-4b56-9e7a-daca1d5fb164">

### 활성함수가 없으면 뉴럴네트워크가 아님 (Activation Function)

<img width="525" alt="스크린샷 2024-08-01 오전 12 39 31" src="https://github.com/user-attachments/assets/a2b51419-0426-481d-a3ca-c29ac34671a0">
<img width="878" alt="스크린샷 2024-08-01 오전 12 39 57" src="https://github.com/user-attachments/assets/1bf5b54c-faad-402d-9daa-753b83506adc">

- 활성함수
<img width="535" alt="스크린샷 2024-08-01 오전 12 40 30" src="https://github.com/user-attachments/assets/639e1f84-b79d-4f12-af5a-c31c7709048d">
<img width="812" alt="스크린샷 2024-08-01 오전 12 40 52" src="https://github.com/user-attachments/assets/dd7ac3be-5556-4349-8902-97d46ba1fd01">

- 시그모이드 함수
- 입력값을 0과 1 사이의 값으로 변환
<img width="883" alt="스크린샷 2024-08-01 오전 12 41 21" src="https://github.com/user-attachments/assets/2d99d667-097e-4281-a360-59865cf69918">

- 하이퍼볼릭 탄젠트 함수(Tanh)
- 입력값을 -1과 1 사이로 변환
<img width="876" alt="스크린샷 2024-08-01 오전 12 41 39" src="https://github.com/user-attachments/assets/93789d5a-a424-406b-b971-c756465784b7">

- 렐루 함수(ReLU)
- 양수는 그대로 유지하고, 음수는 0으로 변환
<img width="409" alt="스크린샷 2024-08-01 오전 12 42 31" src="https://github.com/user-attachments/assets/68eeb0ca-ad3c-43ce-8bf9-1ad51e8bce34">

- 비선형적인 예측 가능
<img width="688" alt="스크린샷 2024-08-01 오전 12 43 12" src="https://github.com/user-attachments/assets/9b218c3f-18b8-4306-af3a-e081e229c33e">
<img width="690" alt="스크린샷 2024-08-01 오전 12 43 30" src="https://github.com/user-attachments/assets/e24f3172-be4f-4fbf-adb3-9fe1fe2d88cb">

- 출력값 
<img width="556" alt="스크린샷 2024-08-01 오전 12 44 15" src="https://github.com/user-attachments/assets/33853ce9-702b-4925-a0da-3ebae9ef7222">

### 신나는 경사하강법
지난 시간까지 강의를 잘 들으셨다면, 이제 뉴럴 네트워크를 통해 예측 값을 계산하는 방법을 이해하셨을 겁니다. 예를 들어, 6월 성적과 같은 데이터를 입력하면, 가중치 
𝑤
w 를 곱하여 
ℎ
1
h 
1
​
  값을 만들어냅니다. 그러나 이 값을 그대로 다음으로 전달하는 것이 아니라, 시그모이드 함수와 같은 활성화 함수에 넣어 변환합니다. 이를 통해 변환된 값을 다음 노드로 전달하며, 최종 예측 값을 도출합니다.

이 예측 값을 실제 값과 비교하여 오차를 계산하고, 오차를 최소화하는 가중치 
𝑤
w 값을 찾으면 모델의 정확도가 높아집니다. 컴퓨터가 이 과정을 통해 최적의 
𝑤
w 값을 찾는 방법을 간단히 설명해드리겠습니다.

예를 들어, 
𝑤
1
w 
1
​
  하나만 생각해봅시다. 
𝑤
1
w 
1
​
 , 
𝑤
2
w 
2
​
  외에도 여러 가중치가 있지만, 단순화를 위해 
𝑤
1
w 
1
​
  만 고려하겠습니다. 만약 
𝑤
1
w 
1
​
  에 다양한 값을 대입해보면, 총 손실 값이 어떻게 변하는지 알 수 있습니다. 예를 들어, 
𝑤
1
w 
1
​
  의 값이 3일 때의 총 손실을 계산한 후, 손실 값을 최소화하는 방향으로 
𝑤
1
w 
1
​
  을 조정해야 합니다. 이를 위해 경사 하강법(Gradient Descent) 이라는 알고리즘을 사용합니다.

경사 하강법은 가중치가 증가하거나 감소하는 방향을 결정하는 방법입니다. 이를 위해 현재 
𝑤
w 값에서 접선의 기울기를 계산합니다. 예를 들어, 
𝑤
1
w 
1
​
  이 3일 때 기울기가 1이라면, 
𝑤
1
w 
1
​
  을 감소시키는 방향으로 조정해야 합니다. 이 과정은 단순히 기울기를 빼는 것이 아니라, 러닝 레이트(Learning Rate) 라는 상수를 곱하여 조정합니다. 러닝 레이트는 가중치 조정의 크기를 결정하며, 너무 크면 최적점을 지나칠 수 있고, 너무 작으면 학습이 느려질 수 있습니다.

이 과정을 반복하면서 최적의 
𝑤
w 값을 찾아내는 것이 머신 러닝의 학습 과정입니다. 최적의 
𝑤
w 값을 찾기 위해 경사 하강법을 사용하는데, 이때 사용되는 러닝 레이트는 적절히 조정해야 합니다. 이는 실험적으로 설정하며, 일반적으로 0.01 또는 0.001과 같은 소숫점 값을 사용합니다.

또한, 러닝 레이트는 일정하게 유지하는 대신, 학습이 진행됨에 따라 동적으로 조정할 수 있습니다. 이를 위해 옵티마이저(Optimizer) 라는 알고리즘을 사용합니다. 예를 들어, 모멘텀(Momentum) 은 관성을 적용하여 빠르게 수렴할 수 있도록 도와주며, 아다그라드(Adagrad) 와 아담(Adam) 은 학습 속도를 자동으로 조정해주는 알고리즘입니다. 이 중에서도 아담은 대부분의 상황에서 좋은 결과를 제공하는 편입니다.

마지막으로, 기울기라는 개념을 2차원 그래프에서 설명했지만, 실제로는 고차원 공간에서 이루어집니다. 이로 인해 직접적으로 시각화하기 어려운 경우가 많습니다. 따라서, 보다 정확하게 표현하자면, 
𝑤
1
w 
1
​
  의 작은 변화가 손실 값에 얼마나 영향을 미치는지를 계산하여 빼는 것입니다. 이러한 과정은 텐서플로와 같은 라이브러리가 자동으로 처리해주므로, 코드를 작성하는 데 직접적으로 계산할 필요는 없습니다.

이 강의에서는 뉴럴 네트워크의 학습 과정과 경사 하강법의 기본 개념을 설명했습니다. 다음 강의에서는 더 깊이 있는 내용을 다룰 예정이니, 관심 있는 분들은 계속해서 시청해 주세요.

### Tensorflow 2 기초 빠르게 정리

오늘은 텐서플로우의 기초 중의 기초인 텐서(Tensor) 라는 자료형에 대해 알아보겠습니다. 텐서플로우가 설치되어 있다면, 파이썬 파일을 하나 만들어 텐서에 대해 실습해보겠습니다.

먼저, 텐서라는 변수를 만들어보겠습니다. tf.constant라는 함수를 사용하여 다음과 같이 작성해보세요:

python
코드 복사
import tensorflow as tf

tensor = tf.constant([1, 2, 3])
print(tensor)
이 코드를 저장하고 터미널에서 python tensor.py라고 입력하여 파일을 실행해보면, 텐서의 출력 결과가 나옵니다. 텐서플로우 실행 시 처음에는 경고 메시지가 나올 수 있지만, 에러만 없다면 문제 없습니다.

이렇게 만든 텐서는 텐서플로우에서 가장 기본적인 자료형입니다. 파이썬의 리스트나 숫자 자료형과 유사하지만, 텐서플로우에서는 이를 텐서라고 부릅니다. 텐서를 만들 때는 숫자나 리스트를 포함하여 여러 가지 형식을 사용할 수 있습니다.

텐서를 배워야 하는 이유는 간단합니다. 머신러닝에서는 다양한 연산을 수행해야 하며, 특히 많은 데이터와 가중치를 다룰 때 매우 유용합니다. 예를 들어, 입력값 
𝑥
1
x 
1
​
 , 
𝑥
2
x 
2
​
 , 
𝑥
3
x 
3
​
 에 각각의 가중치 
𝑤
1
w 
1
​
 , 
𝑤
2
w 
2
​
 , 
𝑤
3
w 
3
​
 를 곱하여 새로운 노드를 만드는 과정에서 수많은 연산이 필요합니다. 이때, 텐서를 이용하면 복잡한 연산을 간단하게 수행할 수 있습니다.

텐서는 행렬과 유사한 구조를 가지며, 여러 숫자를 한 번에 처리할 수 있습니다. 예를 들어, 다음과 같이 텐서 두 개를 더해보겠습니다:

```python
tensor1 = tf.constant([1, 2, 3])
tensor2 = tf.constant([4, 5, 6])
result = tf.add(tensor1, tensor2)
print(result)
```
이 코드를 실행하면 각각의 요소가 더해진 결과를 출력합니다. 텐서 연산은 이렇게 간단하게 수행할 수 있습니다. 텐서 연산에는 더하기, 빼기, 곱하기 등의 다양한 연산이 포함됩니다.

다음으로, 다차원 텐서에 대해 알아보겠습니다. 텐서는 리스트 안에 리스트를 포함하여 다차원 구조를 가질 수 있습니다. 예를 들어, 다음과 같이 2차원 텐서를 만들 수 있습니다:

```python
tensor3 = tf.constant([[1, 2], [3, 4]])
print(tensor3)
```
이 코드는 2행 2열의 텐서를 생성합니다. 이처럼 텐서는 다양한 차원과 모양으로 만들 수 있습니다. 텐서의 모양(shape)을 확인하기 위해 다음과 같이 코드를 작성할 수 있습니다:

```python
print(tensor3.shape)
```
이 코드를 실행하면 텐서의 차원을 알려주는 (2, 2)와 같은 결과가 출력됩니다. 이는 2개의 차원과 각 차원의 크기를 의미합니다. 텐서의 모양은 데이터 분석 시 매우 중요한 정보입니다.

또한, 텐서의 데이터 타입도 중요한 요소입니다. 텐서의 데이터 타입은 dtype 속성을 통해 확인할 수 있습니다. 예를 들어, 정수를 저장하면 int32, 실수를 저장하면 float32와 같이 나타납니다. 보통 딥러닝에서는 실수 자료형을 주로 사용합니다.

마지막으로, 변수(Variable) 라는 특별한 텐서 유형에 대해 알아보겠습니다. 변수를 사용하면 텐서의 값을 변경할 수 있습니다. 예를 들어, 가중치와 같은 값을 저장하고 싶을 때 변수를 사용할 수 있습니다.

```python
variable = tf.Variable([1.0, 2.0, 3.0])
print(variable)
```
변수는 tf.constant와는 달리 값을 수정할 수 있으며, variable.assign(new_value)를 통해 값을 변경할 수 있습니다.

지금까지 텐서플로우의 기본적인 텐서 자료형에 대해 알아보았습니다. 이 내용은 딥러닝과 뉴럴 네트워크의 기초를 이해하는 데 중요한 역할을 합니다. 앞으로의 강의에서는 이 개념을 바탕으로 실제 뉴럴 네트워크를 구축하고 학습하는 방법에 대해 다룰 예정이니, 계속해서 시청해 주세요.

### Tensorflow 2로 해보는 간단한 Linear Regression 선형회귀 예측

이제 본격적으로 실전 프로젝트로 넘어가기 전에, 텐서플로우에서 딥러닝이 어떤 식으로 이루어지는지 간단한 수학 문제를 통해 설명해 드리겠습니다. 예를 들어, 사람들의 키와 신발 사이즈 데이터를 수집했다고 가정해봅시다. 각 사람의 키와 신발 사이즈가 다음과 같이 주어졌습니다:

키: 170cm, 신발 사이즈: 260
키: 180cm, 신발 사이즈: 270
...
이 데이터를 기반으로, 키와 신발 사이즈 사이의 관계를 찾아보겠습니다. 우리는 다음과 같은 식을 세울 수 있습니다:

`신발 사이즈 = a×키+b`

여기서 a와 b는 찾고자 하는 미지수입니다. 예를 들어, 키가 170cm인 사람이 신발 사이즈가 260이라고 한다면, 우리는 이 데이터를 바탕으로 a와 b를 구할 수 있습니다.

이 문제를 풀기 위해, 다음과 같이 간단한 모델을 설정해보겠습니다. 키가 170cm이고, 신발 사이즈가 260인 데이터를 사용하여 예측 모델을 만들어보겠습니다.

먼저, 텐서플로우에서 변수를 정의합니다:

```python
import tensorflow as tf

a = tf.Variable(0.1)
b = tf.Variable(0.2)
```
tf.Variable을 사용하여 초기값을 설정하고, 경사 하강법을 통해 학습을 진행할 수 있도록 합니다. 이제 옵티마이저를 정의해보겠습니다:

```python
optimizer = tf.keras.optimizers.Adam(learning_rate=0.15)
```
Adam 옵티마이저는 경사 하강법을 이용하여 변수들을 업데이트해줍니다. 이어서, 손실 함수를 정의합니다. 손실 함수는 예측 값과 실제 값 사이의 오차를 계산하는 함수입니다. 여기서는 간단히 평균 제곱 오차(MSE)를 사용합니다:

```python
def loss_fn():
    y_pred = a * 170 + b
    y_true = 260
    return tf.square(y_pred - y_true)
```
이제 경사 하강법을 적용하여 학습을 진행합니다. 이를 위해 옵티마이저의 apply_gradients 메소드를 사용합니다:

```python
for _ in range(300):
    optimizer.minimize(loss_fn, var_list=[a, b])
    print(a.numpy(), b.numpy())
```
이 코드는 300번의 반복을 통해 최적의 a와 b 값을 찾습니다. 최종적으로, a와 b 값이 업데이트되면서 점점 더 정확한 예측 모델이 형성됩니다.

이렇게 학습이 완료되면, 우리는 새로운 키 값을 입력하여 신발 사이즈를 예측할 수 있습니다. 예를 들어, 키가 180cm인 사람의 신발 사이즈를 예측해보면 다음과 같습니다:

```python
predicted_shoe_size = a.numpy() * 180 + b.numpy()
print(predicted_shoe_size)
```
이렇게 간단한 선형 모델을 사용하여 키와 신발 사이즈 사이의 관계를 예측할 수 있습니다. 물론, 실제로는 더 복잡한 모델과 데이터를 다루게 되지만, 이 예제는 기본적인 개념을 이해하는 데 도움을 줄 것입니다.

이후에는 더 많은 데이터를 사용하여 보다 복잡한 모델을 학습시키는 방법을 다룰 예정입니다. 이 강의는 가벼운 마음으로 참고하시고, 더 진보된 딥러닝 모델에 대해 배울 준비를 해보세요.

### 대학 합격 예측 AI 만들기 (풀버전)
#### (Part 1) Keras로 모델 만들기
안녕하세요! 첫 번째 프로젝트로 딥러닝 모델을 만들어보겠습니다. 이번에는 학점과 영어 성적 데이터를 이용해 대학원 입학 여부를 예측해보려고 합니다. 첨부 파일을 보시면 여러 사람의 대학원 입학 정보가 있습니다. 예를 들어, 어떤 사람은 영어 성적이 380점이고 학점이 3.2점이며 랭크 3인 대학교에 지원했다고 가정합시다. 그리고 '어드미션'이라는 열에는 이 사람이 합격했는지 여부가 기록되어 있습니다. 1은 합격, 0은 불합격을 의미합니다.

이 데이터를 이용해 학습을 시키고, 새로운 학생이 주어진 조건에서 입학할 확률을 예측하는 모델을 만들어보겠습니다. 목표는 학점과 영어 성적, 대학교 랭크를 입력하면 합격 확률을 예측하는 것입니다.

1. 프로젝트 설정
먼저, Python 파일을 생성하고 필요한 라이브러리를 임포트합니다:

```python
import tensorflow as tf
from tensorflow.keras import layers
```
Keras는 텐서플로우에 포함된 고수준 API로, 딥러닝 모델을 쉽게 만들 수 있게 도와줍니다. 이제 딥러닝 모델을 구성해보겠습니다. 모델은 여러 개의 레이어로 구성되며, 각 레이어는 노드로 구성됩니다. 이때, 각 레이어의 노드 수는 사용자가 지정할 수 있습니다.

2. 모델 구성
```python
model = tf.keras.Sequential([
    layers.Dense(64, activation='relu'),
    layers.Dense(128, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])
```
위 코드에서 첫 번째 레이어는 64개의 노드로 구성되고, 두 번째 레이어는 128개의 노드로 구성됩니다. 마지막 레이어는 1개의 노드로 구성되며, 0과 1 사이의 확률 값을 출력하는 sigmoid 활성화 함수를 사용합니다.

3. 모델 컴파일
모델을 컴파일할 때는 옵티마이저, 손실 함수, 메트릭스를 정의합니다.

```python
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
```
옵티마이저: 경사 하강법을 사용해 모델을 학습시킵니다. adam 옵티마이저는 일반적으로 좋은 성능을 보입니다.
손실 함수: binary_crossentropy를 사용해 0과 1 사이의 확률을 예측합니다.
메트릭스: 모델의 성능을 평가하는 기준으로, 여기서는 정확도(accuracy)를 사용합니다.

4. 모델 학습
이제 모델을 학습시킵니다. 데이터를 준비하여 학습시키는 방법은 다음과 같습니다.

#### (Part 2) 데이터 준비하기
1. 데이터 로드
```python
import pandas as pd

data = pd.read_csv('admission_data.csv')
```
Pandas를 사용하여 CSV 파일을 읽어옵니다. CSV 파일에는 학점, 영어 성적, 대학교 랭크, 입학 여부 등의 정보가 담겨 있습니다.

2. 데이터 전처리
데이터를 학습시키기 전에 결측치를 처리하고 필요한 부분을 추출합니다.

```python
data = data.dropna()
```
이 코드는 데이터에서 결측치가 있는 행을 제거합니다. 필요에 따라 결측치를 특정 값으로 채울 수도 있습니다.

3. 데이터 준비
모델에 입력할 X 데이터와 출력할 y 데이터를 준비합니다.

```python
X = data[['GRE Score', 'GPA', 'Rank']].values
y = data['Admission'].values
```
여기서는 'GRE Score', 'GPA', 'Rank'를 입력 데이터로 사용하고, 'Admission'을 출력 데이터로 사용합니다.

### (Part 3) 학습시키기 & 예측해보기
1. 모델 학습
이제 준비된 데이터를 사용해 모델을 학습시킵니다.

```python
model.fit(X, y, epochs=100)
```
epochs는 전체 데이터셋을 몇 번 반복해서 학습할 것인지를 결정합니다. 여기서는 100번 학습합니다.

2. 예측
모델이 학습된 후, 새로운 데이터를 입력하여 예측을 수행할 수 있습니다.

```python
new_data = np.array([[750, 3.7, 3], [400, 2.1, 1]])
predictions = model.predict(new_data)
print(predictions)
```
predict 메서드를 사용해 새로운 데이터의 입학 확률을 예측합니다. 예를 들어, 첫 번째 데이터는 GRE 750, GPA 3.7, 랭크 3인 학생이 61% 확률로 합격할 것이라고 예측합니다. 두 번째 데이터는 낮은 확률로 불합격할 가능성이 큽니다.

이처럼, Keras와 텐서플로우를 사용해 간단한 딥러닝 모델을 만들고, 학습시키고, 예측할 수 있습니다. 데이터 전처리, 하이퍼파라미터 튜닝 등의 추가적인 작업을 통해 모델의 성능을 더욱 향상시킬 수 있습니다. 이를 통해 여러분은 보다 정확한 예측을 할 수 있는 모델을 만들 수 있습니다.
